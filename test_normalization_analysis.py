#!/usr/bin/env python3
"""
Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· normalized vs unnormalized embeddings Î³Î¹Î± semantic search.
Î”Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ Ï€ÏŒÏ„Îµ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ normalization ÎºÎ±Î¹ Ï€ÏŒÏ„Îµ ÏŒÏ‡Î¹.
"""

import sys
import os
sys.path.insert(0, os.path.abspath('.'))

import numpy as np
from typing import List


def normalize_embedding(embedding: List[float]) -> List[float]:
    """Normalize embedding to unit length (norm = 1)."""
    emb_array = np.array(embedding)
    norm = np.linalg.norm(emb_array)
    if norm == 0:
        return embedding
    return (emb_array / norm).tolist()


def test_normalization_effects():
    """Î”Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ Ï„Î¹Ï‚ ÎµÏ€Î¹Ï€Ï„ÏÏƒÎµÎ¹Ï‚ Ï„Î·Ï‚ normalization."""
    print("ğŸ§ª Normalization Effects on Similarity Calculation")
    print("=" * 60)
    
    # Mock embeddings Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ norms (ÏŒÏ€Ï‰Ï‚ Ï„Î± Î´Î¹ÎºÎ¬ Î¼Î±Ï‚)
    base_vector = np.array([1.5, -0.8, 2.1, -1.2, 0.9])
    
    # Test cases Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ magnitude
    embeddings = [
        base_vector * 10,      # norm ~21 (ÏŒÏ€Ï‰Ï‚ Ï„Î± Î´Î¹ÎºÎ¬ Î¼Î±Ï‚)
        base_vector * 20,      # norm ~42
        base_vector * 5,       # norm ~10.5
        base_vector,           # norm ~2.1
    ]
    
    queries = [
        base_vector * 10 + np.random.normal(0, 0.1, 5),  # Î Î±ÏÏŒÎ¼Î¿Î¹Î¿
        base_vector * 10 + np.random.normal(0, 5, 5),    # ÎšÎ¬Ï€Ï‰Ï‚ Ï€Î±ÏÏŒÎ¼Î¿Î¹Î¿
    ]
    
    print("ğŸ“ Embedding Norms:")
    for i, emb in enumerate(embeddings):
        print(f"  Embedding {i+1}: norm = {np.linalg.norm(emb):.2f}")
    print()
    
    for q_idx, query in enumerate(queries):
        print(f"ğŸ” Query {q_idx+1} (norm = {np.linalg.norm(query):.2f}):")
        print(f"{'Method':<20} {'Emb1':<8} {'Emb2':<8} {'Emb3':<8} {'Emb4':<8}")
        print("-" * 60)
        
        # 1. L2 Distance (current ChromaDB method)
        l2_distances = [np.linalg.norm(query - emb) for emb in embeddings]
        l2_similarities = [1.0 / (1.0 + d) for d in l2_distances]
        print(f"{'L2 + Our Method':<20} {l2_similarities[0]:.3f}  {l2_similarities[1]:.3f}  {l2_similarities[2]:.3f}  {l2_similarities[3]:.3f}")
        
        # 2. Cosine Similarity (raw)
        cosine_sims = []
        for emb in embeddings:
            cos_sim = np.dot(query, emb) / (np.linalg.norm(query) * np.linalg.norm(emb))
            cosine_sims.append(cos_sim)
        print(f"{'Cosine (raw)':<20} {cosine_sims[0]:.3f}  {cosine_sims[1]:.3f}  {cosine_sims[2]:.3f}  {cosine_sims[3]:.3f}")
        
        # 3. Normalized embeddings + L2
        norm_query = query / np.linalg.norm(query)
        norm_embeddings = [emb / np.linalg.norm(emb) for emb in embeddings]
        norm_l2_distances = [np.linalg.norm(norm_query - norm_emb) for norm_emb in norm_embeddings]
        norm_l2_similarities = [1.0 / (1.0 + d) for d in norm_l2_distances]
        print(f"{'Normalized + L2':<20} {norm_l2_similarities[0]:.3f}  {norm_l2_similarities[1]:.3f}  {norm_l2_similarities[2]:.3f}  {norm_l2_similarities[3]:.3f}")
        
        # 4. Normalized embeddings + Cosine (should be identical to #3)
        norm_cosine_sims = []
        for norm_emb in norm_embeddings:
            cos_sim = np.dot(norm_query, norm_emb)  # dot product Î³Î¹Î± normalized vectors
            norm_cosine_sims.append(cos_sim)
        print(f"{'Normalized + Cosine':<20} {norm_cosine_sims[0]:.3f}  {norm_cosine_sims[1]:.3f}  {norm_cosine_sims[2]:.3f}  {norm_cosine_sims[3]:.3f}")
        print()


def test_real_world_scenarios():
    """Î”Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ scenarios Î±Ï€ÏŒ Ï„Î¿ FAQ system."""
    print("ğŸŒ Real-World FAQ Scenarios")
    print("=" * 60)
    
    # Simulated embeddings Î³Î¹Î± Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚
    scenarios = {
        "Identical questions": {
            "query": np.array([2.1, -1.5, 0.8, 1.9, -0.7]) * 15,
            "target": np.array([2.1, -1.5, 0.8, 1.9, -0.7]) * 15 + np.random.normal(0, 0.1, 5)
        },
        "Similar questions": {
            "query": np.array([1.8, -1.2, 1.1, 1.7, -0.9]) * 15,
            "target": np.array([1.9, -1.3, 0.9, 1.8, -0.8]) * 15
        },
        "Related topics": {
            "query": np.array([1.5, -0.8, 2.1, -1.2, 0.9]) * 15,
            "target": np.array([0.9, -1.1, 1.8, -0.7, 1.3]) * 15
        },
        "Different topics": {
            "query": np.array([1.5, -0.8, 2.1, -1.2, 0.9]) * 15,
            "target": np.array([-0.5, 2.2, -1.8, 0.3, -1.7]) * 15
        }
    }
    
    print(f"{'Scenario':<20} {'L2+Our':<8} {'Cosine':<8} {'Norm+L2':<8} {'Recommendation'}")
    print("-" * 70)
    
    for scenario_name, data in scenarios.items():
        query = data["query"]
        target = data["target"]
        
        # Method 1: L2 + Our conversion (current)
        l2_dist = np.linalg.norm(query - target)
        our_sim = 1.0 / (1.0 + l2_dist)
        
        # Method 2: True cosine similarity
        cosine_sim = np.dot(query, target) / (np.linalg.norm(query) * np.linalg.norm(target))
        
        # Method 3: Normalized + L2
        norm_query = query / np.linalg.norm(query)
        norm_target = target / np.linalg.norm(target)
        norm_l2_dist = np.linalg.norm(norm_query - norm_target)
        norm_l2_sim = 1.0 / (1.0 + norm_l2_dist)
        
        # Recommendation based on the scenario
        if scenario_name == "Identical questions":
            recommendation = "All good" if our_sim > 0.4 else "Need norm"
        elif scenario_name == "Similar questions":
            recommendation = "All good" if our_sim > 0.1 else "Need norm"
        else:
            recommendation = "All good" if our_sim < 0.1 else "Too high"
        
        print(f"{scenario_name:<20} {our_sim:.3f}    {cosine_sim:.3f}    {norm_l2_sim:.3f}    {recommendation}")


def analyze_chromadb_options():
    """Î‘Î½Î±Î»ÏÎµÎ¹ Ï„Î¹Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î­Ï‚ Î³Î¹Î± Ï„Î¿ ChromaDB setup."""
    print("\nğŸ”§ ChromaDB Configuration Analysis")
    print("=" * 60)
    
    print("ğŸ“‹ Options:")
    print("1. Keep current setup (unnormalized embeddings + L2 + our conversion)")
    print("2. Normalize embeddings before storing")
    print("3. Use cosine distance in ChromaDB (if supported)")
    print()
    
    print("âœ… Pros & Cons:")
    print("Option 1 (Current - FIXED):")
    print("  âœ“ No changes needed to existing embeddings")
    print("  âœ“ Our conversion works well for L2 distances")  
    print("  âœ“ Preserves embedding magnitude information")
    print("  âš  Slightly different from true cosine similarity")
    print()
    
    print("Option 2 (Normalization):")
    print("  âœ“ More theoretically sound (cosine = dot product)")
    print("  âœ“ Consistent with most ML practices")
    print("  âœ— Need to recreate all embeddings")
    print("  âœ— Lose magnitude information")
    print()
    
    print("Option 3 (Cosine distance):")
    print("  âœ“ Most accurate similarity measure")
    print("  âœ— May not be supported in ChromaDB version")
    print("  âœ— Still need to recreate collection")
    print()
    
    print("ğŸ’¡ Recommendation:")
    print("For your FAQ system, OPTION 1 (current fixed) is BEST because:")
    print("- The fix works very well in practice")  
    print("- No need to recreate embeddings")
    print("- Performance difference is minimal")
    print("- Rankings are now correct and intuitive")


if __name__ == "__main__":
    test_normalization_effects()
    test_real_world_scenarios()
    analyze_chromadb_options()
