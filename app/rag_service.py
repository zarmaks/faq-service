"""
Hybrid RAG Service - Î£Ï…Î½Î´Ï…Î¬Î¶ÎµÎ¹ semantic ÎºÎ±Î¹ keyword search.

Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÎºÎµÎ½Ï„ÏÎ¹ÎºÏŒ service Ï€Î¿Ï… ÎµÎ½Î¿ÏÏ‡Î·ÏƒÏ„ÏÏÎ½ÎµÎ¹ ÏŒÎ»Î± Ï„Î± components:
- Parser Î³Î¹Î± Î½Î± Î´Î¹Î±Î²Î¬ÏƒÎµÎ¹ Ï„Î¿ knowledge base
- Embeddings Î³Î¹Î± semantic         # Î’Î®Î¼Î± 4: Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
        final_results = list(results_map.values())
        
        # Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎºÎ±Ï„Î¬ combined score
        final_results.sort(key=lambda x: x.combined_score, reverse=True)
        
        # ÎšÏÎ±Ï„Î¬Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î± top n_results
        final_results = final_results[:n_results]ng
- ChromaDB Î³Î¹Î± semantic search
- TF-IDF Î³Î¹Î± keyword search
- Scoring ÎºÎ±Î¹ ranking Î³Î¹Î± Ï„Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
"""

from typing import List, Dict, Tuple, Optional
import logging
from dataclasses import dataclass
import os

from .kb_parser import KnowledgeBaseParser, QAPair
from .embeddings_service import EmbeddingsService
from .chromadb_service import ChromaDBService, SearchResult
from .tfidf_service import TFIDFService

logger = logging.getLogger(__name__)


@dataclass
class HybridSearchResult:
    """
    Î¤Î¿ Ï„ÎµÎ»Î¹ÎºÏŒ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± Ï„Î¿Ï… hybrid search.
    
    Î ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚
    ÎºÎ±Î¹ Î­Î½Î± combined score Ï€Î¿Ï… Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï„Î· ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ® ÏƒÏ‡ÎµÏ„Î¹ÎºÏŒÏ„Î·Ï„Î±.
    """
    qa_pair: QAPair
    semantic_score: float      # Score Î±Ï€ÏŒ ChromaDB (0-1)
    keyword_score: float       # Score Î±Ï€ÏŒ TF-IDF (0-1)
    combined_score: float      # Weighted combination (0-1)
    match_type: str           # "semantic", "keyword", or "both"
    explanation: str          # Î“Î¹Î±Ï„Î¯ ÎµÏ€Î¹Î»Î­Ï‡Î¸Î·ÎºÎµ Î±Ï…Ï„ÏŒ Ï„Î¿ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±


class HybridRAGService:
    """
    Î— ÎºÏÏÎ¹Î± ÎºÎ»Î¬ÏƒÎ· Ï€Î¿Ï… ÏƒÏ…Î½Î´Ï…Î¬Î¶ÎµÎ¹ ÏŒÎ»Î± Ï„Î± RAG components.
    
    Î‘Ï…Ï„Î® Î· ÎºÎ»Î¬ÏƒÎ·:
    1. Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ ÎºÎ±Î¹ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î¿ knowledge base
    2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ embeddings ÎºÎ±Î¹ indexes
    3. Î•ÎºÏ„ÎµÎ»ÎµÎ¯ hybrid search
    4. Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î³Î¹Î± Ï„Î¿ LLM
    """
    
    def __init__(
        self,
        knowledge_base_path: str,
        semantic_weight: float = 0.6,
        keyword_weight: float = 0.4
    ):
        """
        Initialize Hybrid RAG Service.
        
        Args:
            knowledge_base_path: Path ÏƒÏ„Î¿ knowledge base file
            semantic_weight: Î ÏŒÏƒÎ¿ Î²Î¬ÏÎ¿Ï‚ Î´Î¯Î½Î¿Ï…Î¼Îµ ÏƒÏ„Î¿ semantic search (0-1)
            keyword_weight: Î ÏŒÏƒÎ¿ Î²Î¬ÏÎ¿Ï‚ Î´Î¯Î½Î¿Ï…Î¼Îµ ÏƒÏ„Î¿ keyword search (0-1)
        """
        self.kb_path = knowledge_base_path
        self.semantic_weight = semantic_weight
        self.keyword_weight = keyword_weight
        
        # Î•Ï€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ· ÏŒÏ„Î¹ Ï„Î± weights Î±Î¸ÏÎ¿Î¯Î¶Î¿Ï…Î½ ÏƒÎµ 1
        assert abs(semantic_weight + keyword_weight - 1.0) < 0.01, \
            "Weights must sum to 1.0"
        
        # Initialize ÏŒÎ»Î± Ï„Î± services
        self.parser = KnowledgeBaseParser(knowledge_base_path)
        self.embeddings_service = EmbeddingsService()
        self.chromadb_service = ChromaDBService()
        self.tfidf_service = TFIDFService()
        
        # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ indexing Ï„Î¿Ï… knowledge base
        self._initialize_knowledge_base()
    
    def _initialize_knowledge_base(self):
        """
        Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ knowledge base ÎºÎ±Î¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ ÏŒÎ»Î± Ï„Î± indexes.
        
        Î‘Ï…Ï„Î® Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± Ï„ÏÎ­Ï‡ÎµÎ¹ Î¼Î¯Î± Ï†Î¿ÏÎ¬ ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·:
        1. Parse Q&A pairs
        2. Create embeddings  
        3. Store in ChromaDB
        4. Create TF-IDF index
        """
        logger.info("ğŸš€ Initializing Hybrid RAG Service...")
        
        # Î’Î®Î¼Î± 1: Parse knowledge base
        logger.info("ğŸ“– Parsing knowledge base...")
        self.qa_pairs = self.parser.parse()
        logger.info(f"   Found {len(self.qa_pairs)} Q&A pairs")
        
        # Î’Î®Î¼Î± 2: Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± texts Î³Î¹Î± indexing
        texts = [qa.to_text() for qa in self.qa_pairs]
        qa_dicts = [qa.to_dict() for qa in self.qa_pairs]
        
        # Î’Î®Î¼Î± 3: Create embeddings
        logger.info("ğŸ§® Creating embeddings...")
        embeddings = self.embeddings_service.create_embeddings_batch(
            texts, 
            show_progress=True
        )
        
        # Î’Î®Î¼Î± 4: Store in ChromaDB
        logger.info("ğŸ’¾ Storing in ChromaDB...")
        self.chromadb_service.add_embeddings(
            embeddings, 
            qa_dicts,
            force_reset=True  # ÎšÎ±Î¸Î±ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï€Î±Î»Î¹Î¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
        )
        
        # Î’Î®Î¼Î± 5: Create TF-IDF index
        logger.info("ğŸ“Š Creating TF-IDF index...")
        self.tfidf_service.fit(texts, qa_dicts)
        
        logger.info("âœ… Hybrid RAG Service initialized successfully!")
    
    def search(
        self,
        query: str,
        n_results: int = 5
    ) -> List[HybridSearchResult]:
        """
        Î•ÎºÏ„ÎµÎ»ÎµÎ¯ hybrid search Î³Î¹Î± Î¼Î¹Î± ÎµÏÏÏ„Î·ÏƒÎ·.
        
        Î— Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±:
        1. Semantic search Î¼Î­ÏƒÏ‰ ChromaDB
        2. Keyword search Î¼Î­ÏƒÏ‰ TF-IDF
        3. Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ scoring
        4. Ranking ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Ï„Ï‰Î½ ÎºÎ±Î»ÏÏ„ÎµÏÏ‰Î½
        
        Args:
            query: Î— ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·
            n_results: ÎœÎ­Î³Î¹ÏƒÏ„Î¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
            
        Returns:
            List of HybridSearchResult, Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î± ÎºÎ±Ï„Î¬ combined score
        """
        logger.info(f"ğŸ” Hybrid search for: '{query}'")
        
        # Î’Î®Î¼Î± 1: Semantic Search
        query_embedding = self.embeddings_service.create_embedding(query)
        semantic_results = self.chromadb_service.search(
            query_embedding, 
            n_results=n_results
        )
        
        # Î’Î®Î¼Î± 2: Keyword Search  
        keyword_results = self.tfidf_service.search(query, n_results=n_results)
        
        # Î’Î®Î¼Î± 3: Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
        results_map = {}  # qa_id -> HybridSearchResult
        
        # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· semantic results
        for result in semantic_results:
            qa_pair = self.parser.get_by_id(result.qa_id)
            
            hybrid_result = HybridSearchResult(
                qa_pair=qa_pair,
                semantic_score=result.similarity,
                keyword_score=0.0,  # Î˜Î± ÎµÎ½Î·Î¼ÎµÏÏ‰Î¸ÎµÎ¯ Î±Î½ Î²ÏÎµÎ¸ÎµÎ¯ ÎºÎ±Î¹ ÏƒÏ„Î¿ TF-IDF
                combined_score=result.similarity * self.semantic_weight,
                match_type="semantic",
                explanation=f"Strong semantic match (score: {result.similarity:.2f})"
            )
            
            results_map[result.qa_id] = hybrid_result
        
        # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ·/ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ· Î¼Îµ keyword results
        for qa_id, keyword_score in keyword_results:
            if qa_id in results_map:
                # Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î· Î±Ï€ÏŒ semantic - ÎµÎ½Î·Î¼ÎµÏÏÎ½Î¿Ï…Î¼Îµ
                result = results_map[qa_id]
                result.keyword_score = keyword_score
                result.combined_score = (
                    result.semantic_score * self.semantic_weight +
                    keyword_score * self.keyword_weight
                )
                result.match_type = "both"
                result.explanation = (
                    f"Both semantic ({result.semantic_score:.2f}) "
                    f"and keyword ({keyword_score:.2f}) match"
                )
            else:
                # ÎÎ­Î¿ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± Î¼ÏŒÎ½Î¿ Î±Ï€ÏŒ keyword
                qa_pair = self.parser.get_by_id(qa_id)
                
                hybrid_result = HybridSearchResult(
                    qa_pair=qa_pair,
                    semantic_score=0.0,
                    keyword_score=keyword_score,
                    combined_score=keyword_score * self.keyword_weight,
                    match_type="keyword",
                    explanation=f"Strong keyword match (score: {keyword_score:.2f})"
                )
                
                results_map[qa_id] = hybrid_result
        
        # Î’Î®Î¼Î± 4: Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
        final_results = list(results_map.values())
        
        # Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÎºÎ±Ï„Î¬ combined score
        final_results.sort(key=lambda x: x.combined_score, reverse=True)
        
        # ÎšÏÎ±Ï„Î¬Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î± top n_results
        final_results = final_results[:n_results]
        
        # Logging Î³Î¹Î± debugging
        logger.info(f"   Semantic results: {len(semantic_results)}")
        logger.info(f"   Keyword results: {len(keyword_results)}")
        logger.info(f"   Combined results: {len(final_results)}")
        
        for i, result in enumerate(final_results[:3]):
            logger.info(
                f"   #{i+1}: {result.qa_pair.question[:50]}... "
                f"(combined: {result.combined_score:.2f}, type: {result.match_type})"
            )
        
        return final_results
    
    def get_context_for_llm(
        self, 
        query: str, 
        max_context_length: int = 2000
    ) -> str:
        """
        Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î¬Î¶ÎµÎ¹ Ï„Î¿ context Î³Î¹Î± Ï„Î¿ LLM Î²Î¬ÏƒÎµÎ¹ Ï„Î·Ï‚ ÎµÏÏÏ„Î·ÏƒÎ·Ï‚.
        
        ÎšÎ¬Î½ÎµÎ¹ search ÎºÎ±Î¹ Î¼Î¿ÏÏ†Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏƒÎµ ÎºÎµÎ¯Î¼ÎµÎ½Î¿
        Ï€Î¿Ï… Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹ Ï„Î¿ LLM Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹.
        
        Args:
            query: Î— ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·
            max_context_length: ÎœÎ­Î³Î¹ÏƒÏ„Î¿ Î¼Î®ÎºÎ¿Ï‚ context ÏƒÎµ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚
            
        Returns:
            Formatted context string Î³Î¹Î± Ï„Î¿ LLM
        """
        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· hybrid search
        results = self.search(query, n_results=6)
        
        if not results:
            return "No relevant information found in the knowledge base."
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± context
        context_parts = []
        total_length = 0
        
        for i, result in enumerate(results):
            # ÎœÎ¿ÏÏ†Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÎ¬Î¸Îµ Q&A pair
            qa_text = f"Q: {result.qa_pair.question}\nA: {result.qa_pair.answer}"
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï‡Ï‰ÏÎ¬ÎµÎ¹ ÏƒÏ„Î¿ context
            if total_length + len(qa_text) > max_context_length:
                break
            
            context_parts.append(qa_text)
            total_length += len(qa_text)
        
        # Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Î¼Îµ Î´Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
        context = "\n\n---\n\n".join(context_parts)
        
        # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· header Î³Î¹Î± Ï„Î¿ LLM
        header = f"Here are the most relevant Q&A pairs for the query '{query}':\n\n"
        
        return header + context
    
    def explain_results(self, query: str) -> Dict:
        """
        Î•Î¾Î·Î³ÎµÎ¯ Ï€ÏÏ‚ Î»ÎµÎ¹Ï„Î¿ÏÏÎ³Î·ÏƒÎµ Ï„Î¿ hybrid search Î³Î¹Î± Î¼Î¹Î± ÎµÏÏÏ„Î·ÏƒÎ·.
        
        Î§ÏÎ®ÏƒÎ¹Î¼Î¿ Î³Î¹Î± debugging ÎºÎ±Î¹ Î³Î¹Î± Î½Î± ÎºÎ±Ï„Î±Î»Î¬Î²Î¿Ï…Î¼Îµ Î³Î¹Î±Ï„Î¯
        ÎµÏ€Î¹Î»Î­Ï‡Î¸Î·ÎºÎ±Î½ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±.
        
        Args:
            query: Î— ÎµÏÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ·
            
        Returns:
            Dictionary Î¼Îµ detailed explanation
        """
        results = self.search(query)
        
        # Î‘Î½Î¬Î»Ï…ÏƒÎ· Ï„Ï‰Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
        semantic_only = [r for r in results if r.match_type == "semantic"]
        keyword_only = [r for r in results if r.match_type == "keyword"]  
        both_match = [r for r in results if r.match_type == "both"]
        
        # Î£Î·Î¼Î±Î½Ï„Î¹ÎºÎ¿Î¯ ÏŒÏÎ¿Î¹ Î±Ï€ÏŒ TF-IDF
        important_terms = self.tfidf_service.get_important_terms(query, top_n=5)
        
        return {
            "query": query,
            "total_results": len(results),
            "semantic_only": len(semantic_only),
            "keyword_only": len(keyword_only),
            "both_match": len(both_match),
            "top_result": {
                "question": results[0].qa_pair.question if results else None,
                "score": results[0].combined_score if results else 0,
                "type": results[0].match_type if results else None
            },
            "important_keywords": important_terms,
            "weights": {
                "semantic": self.semantic_weight,
                "keyword": self.keyword_weight
            }
        }