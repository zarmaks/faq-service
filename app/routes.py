"""
API Routes Î³Î¹Î± Ï„Î¿ FAQ Service.

Î‘Ï…Ï„ÏŒ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ ÏŒÎ»Î± Ï„Î± endpoints.
Î¤Î¿ ÎºÏÎ±Ï„Î¬Î¼Îµ Î¾ÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„ÏŒ Î±Ï€ÏŒ Ï„Î¿ main.py Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ·.
"""

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from typing import List
from datetime import datetime
import logging
import os

from .database import get_db
from .models import Question
from .schemas import QuestionRequest, AnswerResponse, QuestionHistory
from .llm_service import llm_service
from .rag_service import HybridRAGService

# Î¡Ï…Î¸Î¼Î¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ logging
logger = logging.getLogger(__name__)

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î­Î½Î± router Î±Î½Ï„Î¯ Î³Î¹Î± app
# Î‘Ï…Ï„ÏŒ Î¸Î± Ï„Î¿ "ÎºÎ¿Î»Î»Î®ÏƒÎ¿Ï…Î¼Îµ" ÏƒÏ„Î¿ main app Î±ÏÎ³ÏŒÏ„ÎµÏÎ±
router = APIRouter(
    prefix="/api/v1",  # ÎŒÎ»Î± Ï„Î± endpoints Î¸Î± Î¾ÎµÎºÎ¹Î½Î¿ÏÎ½ Î¼Îµ /api/v1
    tags=["faq"],      # Î“Î¹Î± Ï„Î·Î½ Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ· ÏƒÏ„Î¿ documentation
)

# Initialize RAG service - Î¸Î± Î³Î¯Î½ÎµÎ¹ Î¼Î¯Î± Ï†Î¿ÏÎ¬ ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·
rag_service = None

def get_rag_service():
    """Lazy initialization Ï„Î¿Ï… RAG service."""
    global rag_service
    if rag_service is None:
        knowledge_base_path = os.path.join("data", "knowledge_base.txt")
        if not os.path.exists(knowledge_base_path):
            raise FileNotFoundError(f"Knowledge base not found at {knowledge_base_path}")
        rag_service = HybridRAGService(knowledge_base_path)
    return rag_service


@router.post("/ask", response_model=AnswerResponse)
async def ask_question(
    request: QuestionRequest, 
    db: Session = Depends(get_db)
):
    """
    Ask a question to the FAQ system.
    
    Î— Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±:
    1. Î›Î±Î¼Î²Î¬Î½Î¿Ï…Î¼Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î·
    2. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ RAG Î³Î¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ ÏƒÏ‡ÎµÏ„Î¹ÎºÏŒ context
    3. Î£Ï„Î­Î»Î½Î¿Ï…Î¼Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· ÎºÎ±Î¹ Ï„Î¿ context ÏƒÏ„Î¿ LLM
    4. Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Ï…Î¼Îµ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· ÎºÎ±Î¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÏ„Î· Î²Î¬ÏƒÎ·
    5. Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·
    
    Args:
        request: Î— ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·
        db: Database session (injected automatically)
    
    Returns:
        AnswerResponse Î¼Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Ï„Î¿Ï… AI
    """
    try:
        # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿ RAG service
        rag = get_rag_service()
        
        logger.info(f"ğŸ“ Processing question: {request.question[:50]}...")
        
        # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ RAG Î³Î¹Î± Î½Î± Î²ÏÎ¿ÏÎ¼Îµ relevant context
        context = rag.get_context_for_llm(request.question)
        
        logger.info(f"ğŸ” RAG found relevant context ({len(context)} chars)")
        
        # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿ LLM Î¼Îµ Ï„Î¿ context
        answer_text = llm_service.generate_answer_with_context(
            question=request.question,
            context=context
        )
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î½Î­Î¿ record ÏƒÏ„Î· Î²Î¬ÏƒÎ·
        db_question = Question(
            question_text=request.question,
            answer_text=answer_text
        )
        
        # Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Ï…Î¼Îµ ÏƒÏ„Î· Î²Î¬ÏƒÎ·
        db.add(db_question)
        db.commit()
        db.refresh(db_question)  # Î“Î¹Î± Î½Î± Ï€Î¬ÏÎ¿Ï…Î¼Îµ Ï„Î¿ generated ID
        
        logger.info(f"ğŸ’¾ Saved Q&A to database (ID: {db_question.id})")
        
        # Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·
        return AnswerResponse(answer=answer_text)
        
    except Exception as e:
        # Î‘Î½ ÎºÎ¬Ï„Î¹ Ï€Î¬ÎµÎ¹ ÏƒÏ„ÏÎ±Î²Î¬, ÎºÎ¬Î½Î¿Ï…Î¼Îµ rollback
        db.rollback()
        # ÎšÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ user-friendly error
        raise HTTPException(
            status_code=500,
            detail=f"An error occurred while processing your question: {str(e)}"
        )


@router.get("/history", response_model=List[QuestionHistory])
async def get_history(
    n: int = Query(
        default=10,
        ge=1,
        le=100,
        description="Number of questions to return"
    ),
    db: Session = Depends(get_db)
):
    """
    Get the history of recent questions and answers.
    
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î¹Ï‚ Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„ÎµÏ‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚, Î¼Îµ Ï„Î¹Ï‚ Î½ÎµÏŒÏ„ÎµÏÎµÏ‚ Ï€ÏÏÏ„ÎµÏ‚.
    ÎœÏ€Î¿ÏÎµÎ¯Ï‚ Î½Î± ÎµÎ»Î­Î³Î¾ÎµÎ¹Ï‚ Ï€ÏŒÏƒÎµÏ‚ Î¸ÎµÏ‚ Î¼Îµ Ï„Î¿ parameter 'n'.
    
    Args:
        n: Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÏ‰Î½ Ï€Î¿Ï… Î¸Î­Î»ÎµÎ¹Ï‚ (1-100, default: 10)
        db: Database session
    
    Returns:
        List of QuestionHistory objects
    """
    try:
        # Query ÏƒÏ„Î· Î²Î¬ÏƒÎ· - Ï€Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯ÎµÏ‚ n ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚
        questions = db.query(Question)\
            .order_by(Question.timestamp.desc())\
            .limit(n)\
            .all()
        
        # Î¤Î¿ FastAPI Î¸Î± Î¼ÎµÏ„Î±Ï„ÏÎ­ÏˆÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Ï„Î± SQLAlchemy objects
        # ÏƒÎµ QuestionHistory schemas Ï‡Î¬ÏÎ· ÏƒÏ„Î¿ from_attributes=True
        return questions
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving history: {str(e)}"
        )


@router.get("/stats")
async def get_stats(db: Session = Depends(get_db)):
    """
    Get statistics about the FAQ system.
    
    Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Î­Î½Î± bonus endpoint Ï€Î¿Ï… Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï‡ÏÎ®ÏƒÎ¹Î¼Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬.
    ÎšÎ±Î»Î® Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î³Î¹Î± monitoring ÎºÎ±Î¹ debugging.
    """
    try:
        total_questions = db.query(Question).count()
        
        # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î·Î½ Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î· ÎµÏÏÏ„Î·ÏƒÎ·
        latest_question = db.query(Question)\
            .order_by(Question.timestamp.desc())\
            .first()
        
        return {
            "total_questions": total_questions,
            "latest_question_time": latest_question.timestamp if latest_question else None,
            "api_version": "1.0.0",
            "status": "operational"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving stats: {str(e)}"
        )


@router.get("/llm/test")
async def test_llm_connection():
    """
    Test the connection to the LLM service.
    
    Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Ï‡ÏÎ®ÏƒÎ¹Î¼Î¿ Î³Î¹Î± debugging ÎºÎ±Î¹ Î³Î¹Î± Î½Î± Î²ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï‚
    ÏŒÏ„Î¹ Ï„Î¿ Ollama Ï„ÏÎ­Ï‡ÎµÎ¹ ÎºÎ±Î¹ Ï„Î¿ Mistral ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿.
    """
    try:
        test_result = llm_service.test_connection()
        return test_result
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"LLM test failed: {str(e)}"
        )


@router.post("/rag/search")
async def search_knowledge_base(request: QuestionRequest):
    """
    Î•ÎºÏ„ÎµÎ»ÎµÎ¯ RAG search Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± ÎºÎ±Î»Î­ÏƒÎµÎ¹ Ï„Î¿ LLM.
    
    Î‘Ï…Ï„ÏŒ Ï„Î¿ endpoint ÎµÎ¯Î½Î±Î¹ Ï‡ÏÎ®ÏƒÎ¹Î¼Î¿ Î³Î¹Î±:
    - Debugging Ï„Î¿Ï… RAG system
    - ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï„Î¿Ï… Ï€ÏÏ‚ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿ hybrid search
    - Testing Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï€ÎµÏÎ¹Î¼Î­Î½ÎµÎ¹Ï‚ Ï„Î¿ LLM
    
    Returns:
        Detailed search results Î¼Îµ scores ÎºÎ±Î¹ explanations
    """
    try:
        rag = get_rag_service()
        
        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· hybrid search
        results = rag.search(request.question, n_results=5)
        
        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ÏƒÎµ JSON-friendly format
        search_results = []
        for result in results:
            search_results.append({
                "question": result.qa_pair.question,
                "answer": result.qa_pair.answer[:200] + "..." if len(result.qa_pair.answer) > 200 else result.qa_pair.answer,
                "scores": {
                    "semantic": round(result.semantic_score, 3),
                    "keyword": round(result.keyword_score, 3),
                    "combined": round(result.combined_score, 3)
                },
                "match_type": result.match_type,
                "explanation": result.explanation
            })
        
        # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ ÎºÎ±Î¹ explanation Î³Î¹Î± Ï„Î¿ search
        explanation = rag.explain_results(request.question)
        
        return {
            "query": request.question,
            "results": search_results,
            "explanation": explanation,
            "context_preview": rag.get_context_for_llm(request.question)[:500] + "..."
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"RAG search failed: {str(e)}"
        )
async def get_stats(db: Session = Depends(get_db)):
    """
    Get statistics about the FAQ system.
    
    Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Î­Î½Î± bonus endpoint Ï€Î¿Ï… Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ Ï‡ÏÎ®ÏƒÎ¹Î¼Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬.
    ÎšÎ±Î»Î® Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Î³Î¹Î± monitoring ÎºÎ±Î¹ debugging.
    """
    try:
        total_questions = db.query(Question).count()
        
        # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î·Î½ Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î· ÎµÏÏÏ„Î·ÏƒÎ·
        latest_question = db.query(Question)\
            .order_by(Question.timestamp.desc())\
            .first()
        
        return {
            "total_questions": total_questions,
            "latest_question_time": latest_question.timestamp if latest_question else None,
            "api_version": "1.0.0",
            "status": "operational"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving stats: {str(e)}"
        )